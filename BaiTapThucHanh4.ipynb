{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8pq04Py6Ham",
        "outputId": "f362bdba-7384-47ee-a824-1363636c7b48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieving folder contents\n",
            "Processing file 1hoTd2hFwjSeFThlPm6YpN0NW5ePXS3Jc small-dev.json\n",
            "Processing file 1_3L25SH1_jaEfOjpmpgnfMik4N3MxSyn small-test.json\n",
            "Processing file 1-eG6FeF-v__rsf77iWurddahXbyjTYh5 small-train.json\n",
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1hoTd2hFwjSeFThlPm6YpN0NW5ePXS3Jc\n",
            "To: /content/my_data/small-dev.json\n",
            "100% 594k/594k [00:00<00:00, 119MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1_3L25SH1_jaEfOjpmpgnfMik4N3MxSyn\n",
            "To: /content/my_data/small-test.json\n",
            "100% 669k/669k [00:00<00:00, 114MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-eG6FeF-v__rsf77iWurddahXbyjTYh5\n",
            "To: /content/my_data/small-train.json\n",
            "100% 5.68M/5.68M [00:00<00:00, 234MB/s]\n",
            "Download completed\n"
          ]
        }
      ],
      "source": [
        "import gdown\n",
        "import os\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "# Tạo thư mục để chứa dữ liệu\n",
        "os.makedirs('/content/my_data', exist_ok=True)\n",
        "\n",
        "# mount folder cụ thể\n",
        "folder_url = 'https://drive.google.com/drive/folders/186OAOuSEYEDVcry7WP5UBdqECXo26QAb?usp=drive_link'\n",
        "\n",
        "!gdown --folder https://drive.google.com/drive/folders/186OAOuSEYEDVcry7WP5UBdqECXo26QAb?usp=drive_link -O /content/my_data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge-score\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZ-O5SWySmP1",
        "outputId": "45e73dfd-a835-4da5-e285-ac2c7d2dde8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rouge-score in /usr/local/lib/python3.12/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from rouge-score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rouge-score) (2.0.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from rouge-score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->rouge-score) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->rouge-score) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk->rouge-score) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk->rouge-score) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "train_path = \"/content/my_data/small-train.json\"\n",
        "dev_path   = \"/content/my_data/small-dev.json\"\n",
        "test_path  = \"/content/my_data/small-test.json\"\n",
        "\n",
        "# Load dữ liệu\n",
        "with open(train_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    train_data = json.load(f)\n",
        "\n",
        "with open(dev_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    dev_data = json.load(f)\n",
        "\n",
        "with open(test_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    test_data = json.load(f)\n",
        "\n",
        "print(\"Train size:\", len(train_data))\n",
        "print(\"Dev size:\", len(dev_data))\n",
        "print(\"Test size:\", len(test_data))\n"
      ],
      "metadata": {
        "id": "q5sb5XvEPAFC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d2f7fd8-3732-47b0-ec31-7d8d7703e25b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 20000\n",
            "Dev size: 2000\n",
            "Test size: 2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import random\n",
        "import json\n",
        "from typing import List, Tuple, Dict\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Sử dụng thiết bị: {device}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_2DU7_WUB7G",
        "outputId": "488b9d5c-be03-4d8d-c081-6428235885cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sử dụng thiết bị: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Thiết bị\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# Token đặc biệt\n",
        "PAD_TOKEN = \"<pad>\"\n",
        "SOS_TOKEN = \"<sos>\"\n",
        "EOS_TOKEN = \"<eos>\"\n",
        "UNK_TOKEN = \"<unk>\"\n",
        "\n",
        "EMBEDDING_DIM = 256\n",
        "HIDDEN_SIZE = 256\n",
        "NUM_LAYERS = 3\n",
        "BATCH_SIZE = 64\n",
        "N_EPOCHS = 10\n",
        "TEACHER_FORCING_RATIO = 0.5\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjNDdSEeUS2i",
        "outputId": "c01cea09-e486-4312-ff15-bfbb85cc0d97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bài 1: Xây dựng kiến trúc Encoder-Decoder gồm 3 lớp LSTM cho module encoder và 3 lớp LSTM cho module decoder, với hidden size là 256, cho bài toán dịch máy từ tiếng Anh sang tiếng Việt. Huấn luyện mô hình này trên bộ dữ liệu PhoMT sử dụng Adam làm phương thức tối ưu tham số. Đánh giá độ hiệu quả của mô hình sử dụng độ đo ROUGE-L."
      ],
      "metadata": {
        "id": "HpyPHhwfcD4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Vocab:\n",
        "    def __init__(self, min_freq=2):\n",
        "        self.word2idx = {\n",
        "            PAD_TOKEN: 0,\n",
        "            SOS_TOKEN: 1,\n",
        "            EOS_TOKEN: 2,\n",
        "            UNK_TOKEN: 3\n",
        "        }\n",
        "        self.idx2word = {i:w for w,i in self.word2idx.items()}\n",
        "        self.counter = Counter()\n",
        "        self.n_words = 4\n",
        "        self.min_freq = min_freq\n",
        "\n",
        "    def add_sentence(self, sentence):\n",
        "        for w in sentence.split():\n",
        "            self.counter[w] += 1\n",
        "\n",
        "    def build(self):\n",
        "        for w, c in self.counter.items():\n",
        "            if c >= self.min_freq and w not in self.word2idx:\n",
        "                self.word2idx[w] = self.n_words\n",
        "                self.idx2word[self.n_words] = w\n",
        "                self.n_words += 1\n",
        "\n",
        "    def encode(self, sentence):\n",
        "        return [self.word2idx.get(w, self.word2idx[UNK_TOKEN]) for w in sentence.split()]\n",
        "\n",
        "src_vocab = Vocab()\n",
        "tgt_vocab = Vocab()\n",
        "\n",
        "for pair in train_data:\n",
        "    src_vocab.add_sentence(pair[\"english\"])\n",
        "    tgt_vocab.add_sentence(pair[\"vietnamese\"])\n",
        "\n",
        "src_vocab.build()\n",
        "tgt_vocab.build()\n",
        "\n",
        "PAD_IDX = src_vocab.word2idx[PAD_TOKEN]\n",
        "\n",
        "print(\"SRC vocab size:\", src_vocab.n_words)\n",
        "print(\"TGT vocab size:\", tgt_vocab.n_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e30tJnfUfHq",
        "outputId": "2e3e507e-7122-48d6-c705-acd201c9dd5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SRC vocab size: 10721\n",
            "TGT vocab size: 5080\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PhoMTDataset(Dataset):\n",
        "    def __init__(self, data, src_vocab, tgt_vocab):\n",
        "        self.data = data\n",
        "        self.src_vocab = src_vocab\n",
        "        self.tgt_vocab = tgt_vocab\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        src = self.src_vocab.encode(self.data[idx][\"english\"])\n",
        "        tgt = self.tgt_vocab.encode(self.data[idx][\"vietnamese\"])\n",
        "        tgt = [self.tgt_vocab.word2idx[SOS_TOKEN]] + tgt + [self.tgt_vocab.word2idx[EOS_TOKEN]]\n",
        "        return torch.tensor(src), torch.tensor(tgt)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZZzt826fWJwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    srcs, tgts = zip(*batch)\n",
        "    srcs = nn.utils.rnn.pad_sequence(srcs, batch_first=True, padding_value=PAD_IDX)\n",
        "    tgts = nn.utils.rnn.pad_sequence(tgts, batch_first=True, padding_value=PAD_IDX)\n",
        "    return srcs.to(device), tgts.to(device)\n"
      ],
      "metadata": {
        "id": "l5eXvHPsXoJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(\n",
        "    PhoMTDataset(train_data, src_vocab, tgt_vocab),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_fn\n",
        ")\n"
      ],
      "metadata": {
        "id": "qgfTkxxTXpn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, EMBEDDING_DIM, padding_idx=PAD_IDX)\n",
        "        self.lstm = nn.LSTM(\n",
        "            EMBEDDING_DIM,\n",
        "            HIDDEN_SIZE,\n",
        "            num_layers=NUM_LAYERS,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "    def forward(self, src):\n",
        "        embedded = self.embedding(src)\n",
        "        _, (hidden, cell) = self.lstm(embedded)\n",
        "        return hidden, cell\n"
      ],
      "metadata": {
        "id": "hKMLw03RWRFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, EMBEDDING_DIM, padding_idx=PAD_IDX)\n",
        "        self.lstm = nn.LSTM(\n",
        "            EMBEDDING_DIM,\n",
        "            HIDDEN_SIZE,\n",
        "            num_layers=NUM_LAYERS,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.fc = nn.Linear(HIDDEN_SIZE, vocab_size)\n",
        "\n",
        "    def forward(self, input_token, hidden, cell):\n",
        "        embedded = self.embedding(input_token)\n",
        "        output, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
        "        prediction = self.fc(output.squeeze(1))\n",
        "        return prediction, hidden, cell\n"
      ],
      "metadata": {
        "id": "pEfVoDBXWS7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        batch_size = src.size(0)\n",
        "        tgt_len = tgt.size(1)\n",
        "        vocab_size = self.decoder.fc.out_features\n",
        "\n",
        "        outputs = torch.zeros(batch_size, tgt_len-1, vocab_size).to(device)\n",
        "\n",
        "        hidden, cell = self.encoder(src)\n",
        "        decoder_input = tgt[:, 0].unsqueeze(1)\n",
        "\n",
        "        for t in range(1, tgt_len):\n",
        "            output, hidden, cell = self.decoder(decoder_input, hidden, cell)\n",
        "            outputs[:, t-1] = output\n",
        "\n",
        "            use_teacher = random.random() < TEACHER_FORCING_RATIO\n",
        "            top1 = output.argmax(1)\n",
        "            decoder_input = tgt[:, t].unsqueeze(1) if use_teacher else top1.unsqueeze(1)\n",
        "\n",
        "        return outputs\n"
      ],
      "metadata": {
        "id": "wTzy2M-OWVkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encoder(src_vocab.n_words).to(device)\n",
        "decoder = Decoder(tgt_vocab.n_words).to(device)\n",
        "model = Seq2Seq(encoder, decoder).to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n"
      ],
      "metadata": {
        "id": "fPIL6RwaWZek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(N_EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for src, tgt in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, tgt)\n",
        "\n",
        "        loss = criterion(\n",
        "            output.reshape(-1, output.size(-1)),\n",
        "            tgt[:, 1:].reshape(-1)\n",
        "        )\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{N_EPOCHS} - Loss: {total_loss/len(train_loader):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTDa6JtvWaer",
        "outputId": "83f80c0b-03d3-43a7-9fd7-41376f30a2d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Loss: 6.2686\n",
            "Epoch 2/5 - Loss: 6.0120\n",
            "Epoch 3/5 - Loss: 5.8003\n",
            "Epoch 4/5 - Loss: 5.6275\n",
            "Epoch 5/5 - Loss: 5.4756\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bài 2: Xây dựng kiến trúc Encoder-Decoder gồm 3 lớp LSTM cho module encoder và 3 lớp LSTM cho module decoder, với hidden size là 256, cho bài toán dịch máy từ tiếng Anh sang tiếng Việt. Module decoder được trang bị kỹ thuật attention theo mô tả của nghiên cứu \"[Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/abs/1409.0473)\". Huấn luyện mô hình này trên bộ dữ liệu PhoMT sử dụng Adam làm phương thức tối ưu tham số. Đánh giá độ hiệu quả của mô hình sử dụn độ đo ROUGE-L."
      ],
      "metadata": {
        "id": "Od0mShjFcIEZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, EMBEDDING_DIM, padding_idx=PAD_IDX)\n",
        "        self.lstm = nn.LSTM(\n",
        "            EMBEDDING_DIM,\n",
        "            HIDDEN_SIZE,\n",
        "            num_layers=NUM_LAYERS,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "    def forward(self, src):\n",
        "        embedded = self.embedding(src)\n",
        "        outputs, (hidden, cell) = self.lstm(embedded)\n",
        "        return outputs, hidden, cell\n"
      ],
      "metadata": {
        "id": "pCPu7MOFcN4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BahdanauAttention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super().__init__()\n",
        "        self.W1 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.W2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.v = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, decoder_hidden, encoder_outputs):\n",
        "        src_len = encoder_outputs.size(1)\n",
        "\n",
        "        decoder_hidden = decoder_hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "        energy = torch.tanh(\n",
        "            self.W1(encoder_outputs) + self.W2(decoder_hidden)\n",
        "        )\n",
        "\n",
        "        attention = self.v(energy).squeeze(2)\n",
        "        attention_weights = torch.softmax(attention, dim=1)\n",
        "\n",
        "        context = torch.bmm(\n",
        "            attention_weights.unsqueeze(1),\n",
        "            encoder_outputs\n",
        "        ).squeeze(1)\n",
        "\n",
        "        return context, attention_weights\n"
      ],
      "metadata": {
        "id": "4tRg2X5IcRTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderAttention(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, EMBEDDING_DIM, padding_idx=PAD_IDX)\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            EMBEDDING_DIM + HIDDEN_SIZE,\n",
        "            HIDDEN_SIZE,\n",
        "            num_layers=NUM_LAYERS,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        self.attention = BahdanauAttention(HIDDEN_SIZE)\n",
        "        self.fc = nn.Linear(HIDDEN_SIZE * 2, vocab_size)\n",
        "\n",
        "    def forward(self, input_token, hidden, cell, encoder_outputs):\n",
        "        embedded = self.embedding(input_token)\n",
        "\n",
        "        decoder_hidden = hidden[-1]\n",
        "        context, attn_weights = self.attention(decoder_hidden, encoder_outputs)\n",
        "\n",
        "        context = context.unsqueeze(1)\n",
        "        lstm_input = torch.cat((embedded, context), dim=2)\n",
        "\n",
        "        output, (hidden, cell) = self.lstm(lstm_input, (hidden, cell))\n",
        "\n",
        "        prediction = self.fc(\n",
        "            torch.cat((output.squeeze(1), context.squeeze(1)), dim=1)\n",
        "        )\n",
        "\n",
        "        return prediction, hidden, cell, attn_weights\n"
      ],
      "metadata": {
        "id": "j54w61TScT0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2SeqAttention(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        batch_size = src.size(0)\n",
        "        tgt_len = tgt.size(1)\n",
        "        vocab_size = self.decoder.fc.out_features\n",
        "\n",
        "        outputs = torch.zeros(batch_size, tgt_len-1, vocab_size).to(device)\n",
        "\n",
        "        encoder_outputs, hidden, cell = self.encoder(src)\n",
        "        decoder_input = tgt[:, 0].unsqueeze(1)\n",
        "\n",
        "        for t in range(1, tgt_len):\n",
        "            output, hidden, cell, _ = self.decoder(\n",
        "                decoder_input, hidden, cell, encoder_outputs\n",
        "            )\n",
        "\n",
        "            outputs[:, t-1] = output\n",
        "            top1 = output.argmax(1)\n",
        "\n",
        "            decoder_input = (\n",
        "                tgt[:, t].unsqueeze(1)\n",
        "                if random.random() < TEACHER_FORCING_RATIO\n",
        "                else top1.unsqueeze(1)\n",
        "            )\n",
        "\n",
        "        return outputs\n"
      ],
      "metadata": {
        "id": "3U6pbQ5WcVVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encoder(src_vocab.n_words).to(device)\n",
        "decoder = DecoderAttention(tgt_vocab.n_words).to(device)\n",
        "\n",
        "model = Seq2SeqAttention(encoder, decoder).to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n"
      ],
      "metadata": {
        "id": "QgJXSSSOcW7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(N_EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for src, tgt in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, tgt)\n",
        "\n",
        "        loss = criterion(\n",
        "            output.reshape(-1, output.size(-1)),\n",
        "            tgt[:, 1:].reshape(-1)\n",
        "        )\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\" Epoch {epoch+1}/{N_EPOCHS} - Loss: {total_loss/len(train_loader):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5VBJfMLcY1e",
        "outputId": "b15c642b-1a11-4896-c8f3-84b9479d3732"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Epoch 1/10 - Loss: 5.8666\n",
            " Epoch 2/10 - Loss: 5.5696\n",
            " Epoch 3/10 - Loss: 5.2287\n",
            " Epoch 4/10 - Loss: 4.9235\n",
            " Epoch 5/10 - Loss: 4.6527\n",
            " Epoch 6/10 - Loss: 4.4172\n",
            " Epoch 7/10 - Loss: 4.1822\n",
            " Epoch 8/10 - Loss: 3.9768\n",
            " Epoch 9/10 - Loss: 3.7914\n",
            " Epoch 10/10 - Loss: 3.6238\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bài 3: Xây dựng kiến trúc Encoder-Decoder gồm 3 lớp LSTM cho module encoder và 3 lớp LSTM cho module decoder, với hidden size là 256, cho bài toán dịch máy từ tiếng Anh sang tiếng Việt. Module decoder được trang bị kỹ thuật attention theo mô tả của nghiên cứu \"[Effective Approaches to Attention-based Neural Machine Translation](https://arxiv.org/abs/1508.04025)\". Huấn luyện mô hình này trên bộ dữ liệu PhoMT sử dụng Adam làm phương thức tối ưu tham số. Đánh giá độ hiệu quả của mô hình sử dụn độ đo ROUGE-L."
      ],
      "metadata": {
        "id": "5uwUX046lIlJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LuongAttention(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, decoder_hidden, encoder_outputs):\n",
        "        scores = torch.bmm(\n",
        "            encoder_outputs,\n",
        "            decoder_hidden.unsqueeze(2)\n",
        "        ).squeeze(2)\n",
        "\n",
        "        attn_weights = torch.softmax(scores, dim=1)\n",
        "\n",
        "        context = torch.bmm(\n",
        "            attn_weights.unsqueeze(1),\n",
        "            encoder_outputs\n",
        "        ).squeeze(1)\n",
        "\n",
        "        return context, attn_weights\n"
      ],
      "metadata": {
        "id": "TfHcKajomLQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLuong(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, EMBEDDING_DIM, padding_idx=PAD_IDX)\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            EMBEDDING_DIM,\n",
        "            HIDDEN_SIZE,\n",
        "            num_layers=NUM_LAYERS,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        self.attention = LuongAttention()\n",
        "        self.fc = nn.Linear(HIDDEN_SIZE * 2, vocab_size)\n",
        "\n",
        "    def forward(self, input_token, hidden, cell, encoder_outputs):\n",
        "        embedded = self.embedding(input_token)\n",
        "\n",
        "        output, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
        "        decoder_hidden = output.squeeze(1)\n",
        "\n",
        "        context, attn_weights = self.attention(decoder_hidden, encoder_outputs)\n",
        "\n",
        "        prediction = self.fc(\n",
        "            torch.cat((decoder_hidden, context), dim=1)\n",
        "        )\n",
        "\n",
        "        return prediction, hidden, cell, attn_weights\n"
      ],
      "metadata": {
        "id": "eBhZTr9RmDgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2SeqLuong(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        batch_size = src.size(0)\n",
        "        tgt_len = tgt.size(1)\n",
        "        vocab_size = self.decoder.fc.out_features\n",
        "\n",
        "        outputs = torch.zeros(batch_size, tgt_len-1, vocab_size).to(device)\n",
        "\n",
        "        encoder_outputs, hidden, cell = self.encoder(src)\n",
        "        decoder_input = tgt[:, 0].unsqueeze(1)\n",
        "\n",
        "        for t in range(1, tgt_len):\n",
        "            output, hidden, cell, _ = self.decoder(\n",
        "                decoder_input, hidden, cell, encoder_outputs\n",
        "            )\n",
        "\n",
        "            outputs[:, t-1] = output\n",
        "            top1 = output.argmax(1)\n",
        "\n",
        "            decoder_input = (\n",
        "                tgt[:, t].unsqueeze(1)\n",
        "                if random.random() < TEACHER_FORCING_RATIO\n",
        "                else top1.unsqueeze(1)\n",
        "            )\n",
        "\n",
        "        return outputs\n"
      ],
      "metadata": {
        "id": "XZMzfeZ-mOYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encoder(src_vocab.n_words).to(device)\n",
        "decoder = DecoderLuong(tgt_vocab.n_words).to(device)\n",
        "\n",
        "model = Seq2SeqLuong(encoder, decoder).to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n"
      ],
      "metadata": {
        "id": "3Ct9FP15mQjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(N_EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for src, tgt in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, tgt)\n",
        "\n",
        "        loss = criterion(\n",
        "            output.reshape(-1, output.size(-1)),\n",
        "            tgt[:, 1:].reshape(-1)\n",
        "        )\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{N_EPOCHS} - Loss: {total_loss/len(train_loader):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxK0_dnjmSEu",
        "outputId": "ab7f1c95-4271-4402-8c6f-7a693236a5da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 - Loss: 6.2031\n",
            "Epoch 2/10 - Loss: 5.8211\n",
            "Epoch 3/10 - Loss: 5.4783\n",
            "Epoch 4/10 - Loss: 5.1753\n",
            "Epoch 5/10 - Loss: 4.9282\n",
            "Epoch 6/10 - Loss: 4.6970\n",
            "Epoch 7/10 - Loss: 4.4839\n",
            "Epoch 8/10 - Loss: 4.2885\n",
            "Epoch 9/10 - Loss: 4.1127\n",
            "Epoch 10/10 - Loss: 3.9396\n"
          ]
        }
      ]
    }
  ]
}